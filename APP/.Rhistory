message("departements_simplified.rds saved.")
# --- Load, Filter, Simplify, and Save Communes ---
message("Processing commune-frmetdrom.geojson and filtering by population...")
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326) %>% # Ensure WGS84 for Leaflet
# No simplification here yet, do it after filtering
# st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_COMMUNES) # Removed this line for now
# *** CRITICAL: RENAME GeoJSON commune code for joining ***
# Based on your previous output, `CODCOM` is in your CSV.
# This part assumes your GeoJSON has a column named 'INSEE_COM' or 'code' for commune code.
# YOU MUST ENSURE THIS MATCHES YOUR REAL GEOJSON COLUMN NAME!
geojson_commune_code_col_name <- NULL
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # For rename and filter
# --- Configuration: Adjust paths and dTolerance values as needed ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10 # Smaller tolerance for more detail, can be increased for faster loading
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and preprocess CommunesGeo.csv for filtering ---
message("Loading and filtering CommunesGeo.csv...")
if (file.exists(file.path(INPUT_DIR, "CommunesGeo.csv"))) {
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
# Clean column names
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
# Convert relevant columns to numeric and character
# Ensure CODCOM is character for joining
if ("CODCOM" %in% colnames(df_communes_csv)) df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
if ("PMUN" %in% colnames(df_communes_csv)) {
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
} else {
warning("PMUN column not found in CommunesGeo.csv during pre-processing. Cannot filter communes by population.")
}
# Filter by population (10k to 20k)
if ("PMUN" %in% colnames(df_communes_csv) && is.numeric(df_communes_csv$PMUN)) {
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
select(CODCOM) # Select only the join key for now, we'll join full data in app.R
message(paste("Filtered CommunesGeo.csv: Kept", nrow(df_communes_filtered), "communes within 10k-20k PMUN range."))
} else {
df_communes_filtered <- df_communes_csv %>% select(CODCOM) # No population filter applied
message("Communes will not be pre-filtered by population, PMUN column was not available or not numeric.")
}
} else {
stop("CommunesGeo.csv not found at specified path: ", file.path(INPUT_DIR, "CommunesGeo.csv"))
}
# --- Load, Simplify, and Save Regions ---
message("Processing regions.geojson...")
regions <- st_read(file.path(INPUT_DIR, "regions.geojson")) %>%
st_transform(crs = 4326) %>% # Ensure WGS84 for Leaflet
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_REGIONS)
# *** IMPORTANT: VERIFY AND ADJUST THIS RENAME CALL ***
# This assumes your regions.geojson has a column named 'nom' for the region name.
# If it's 'NAME_2', 'LIBGEO', etc., change 'nom' to that.
if ("nom" %in% names(regions)) {
message("Regions: 'nom' column found.")
} else if ("NAME_2" %in% names(regions)) { # Example alternative
regions <- regions %>% rename(nom = NAME_2)
message("Regions: Renamed 'NAME_2' to 'nom'.")
} else if ("libelle" %in% names(regions)) { # Another example
regions <- regions %>% rename(nom = libelle)
message("Regions: Renamed 'libelle' to 'nom'.")
} else {
warning("Regions: 'nom' column not found, and no common alternative found. Please manually rename the region name column in your regions.geojson to 'nom' for accurate joins/display, or adjust this script.")
}
saveRDS(regions, file.path(OUTPUT_DIR, "regions_simplified.rds"))
message("regions_simplified.rds saved.")
# --- Load, Simplify, and Save Departements ---
message("Processing contour-des-departements.geojson...")
departements <- st_read(file.path(INPUT_DIR, "contour-des-departements.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_DEPARTEMENTS)
# *** IMPORTANT: VERIFY AND ADJUST THESE RENAME CALLS ***
# Assumes 'code' for department code and 'nom' for department name.
# Adjust to your actual column names.
if (!"code" %in% names(departements)) {
if ("CODE_DEP" %in% names(departements)) { # Example alternative
departements <- departements %>% rename(code = CODE_DEP)
message("Departements: Renamed 'CODE_DEP' to 'code'.")
} else {
warning("Departements: 'code' column not found. Please manually rename department code column to 'code'.")
}
}
if (!"nom" %in% names(departements)) {
if ("NOM_DEP" %in% names(departements)) { # Example alternative
departements <- departements %>% rename(nom = NOM_DEP)
message("Departements: Renamed 'NOM_DEP' to 'nom'.")
} else {
warning("Departements: 'nom' column not found for display. Please manually rename the department name column to 'nom'.")
}
}
saveRDS(departements, file.path(OUTPUT_DIR, "departements_simplified.rds"))
message("departements_simplified.rds saved.")
# --- Load, Filter, Simplify, and Save Communes ---
message("Processing commune-frmetdrom.geojson and filtering by population...")
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326) %>%
geojson_commune_code_col_name <- NULL
install.packages("magrittr")
install.packages("magrittr")
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
# preprocess_geojson.R
library(sf)
library(magrittr) # <--- ADD THIS LINE
library(dplyr)
# ... rest of your script
# --- Configuration: Adjust paths and dTolerance values as needed ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10 # Smaller tolerance for more detail, can be increased for faster loading
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and preprocess CommunesGeo.csv for filtering ---
message("Loading and filtering CommunesGeo.csv...")
if (file.exists(file.path(INPUT_DIR, "CommunesGeo.csv"))) {
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
# Clean column names
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
# Convert relevant columns to numeric and character
# Ensure CODCOM is character for joining
if ("CODCOM" %in% colnames(df_communes_csv)) df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
if ("PMUN" %in% colnames(df_communes_csv)) {
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
} else {
warning("PMUN column not found in CommunesGeo.csv during pre-processing. Cannot filter communes by population.")
}
# Filter by population (10k to 20k)
if ("PMUN" %in% colnames(df_communes_csv) && is.numeric(df_communes_csv$PMUN)) {
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
select(CODCOM) # Select only the join key for now, we'll join full data in app.R
message(paste("Filtered CommunesGeo.csv: Kept", nrow(df_communes_filtered), "communes within 10k-20k PMUN range."))
} else {
df_communes_filtered <- df_communes_csv %>% select(CODCOM) # No population filter applied
message("Communes will not be pre-filtered by population, PMUN column was not available or not numeric.")
}
} else {
stop("CommunesGeo.csv not found at specified path: ", file.path(INPUT_DIR, "CommunesGeo.csv"))
}
# --- Load, Simplify, and Save Regions ---
message("Processing regions.geojson...")
regions <- st_read(file.path(INPUT_DIR, "regions.geojson")) %>%
st_transform(crs = 4326) %>% # Ensure WGS84 for Leaflet
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_REGIONS)
# *** IMPORTANT: VERIFY AND ADJUST THIS RENAME CALL ***
# This assumes your regions.geojson has a column named 'nom' for the region name.
# If it's 'NAME_2', 'LIBGEO', etc., change 'nom' to that.
if ("nom" %in% names(regions)) {
message("Regions: 'nom' column found.")
} else if ("NAME_2" %in% names(regions)) { # Example alternative
regions <- regions %>% rename(nom = NAME_2)
message("Regions: Renamed 'NAME_2' to 'nom'.")
} else if ("libelle" %in% names(regions)) { # Another example
regions <- regions %>% rename(nom = libelle)
message("Regions: Renamed 'libelle' to 'nom'.")
} else {
warning("Regions: 'nom' column not found, and no common alternative found. Please manually rename the region name column in your regions.geojson to 'nom' for accurate joins/display, or adjust this script.")
}
saveRDS(regions, file.path(OUTPUT_DIR, "regions_simplified.rds"))
message("regions_simplified.rds saved.")
# --- Load, Simplify, and Save Departements ---
message("Processing contour-des-departements.geojson...")
departements <- st_read(file.path(INPUT_DIR, "contour-des-departements.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_DEPARTEMENTS)
# *** IMPORTANT: VERIFY AND ADJUST THESE RENAME CALLS ***
# Assumes 'code' for department code and 'nom' for department name.
# Adjust to your actual column names.
if (!"code" %in% names(departements)) {
if ("CODE_DEP" %in% names(departements)) { # Example alternative
departements <- departements %>% rename(code = CODE_DEP)
message("Departements: Renamed 'CODE_DEP' to 'code'.")
} else {
warning("Departements: 'code' column not found. Please manually rename department code column to 'code'.")
}
}
if (!"nom" %in% names(departements)) {
if ("NOM_DEP" %in% names(departements)) { # Example alternative
departements <- departements %>% rename(nom = NOM_DEP)
message("Departements: Renamed 'NOM_DEP' to 'nom'.")
} else {
warning("Departements: 'nom' column not found for display. Please manually rename the department name column to 'nom'.")
}
}
saveRDS(departements, file.path(OUTPUT_DIR, "departements_simplified.rds"))
message("departements_simplified.rds saved.")
# --- Load, Filter, Simplify, and Save Communes ---
message("Processing commune-frmetdrom.geojson and filtering by population...")
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326) %>%
geojson_commune_code_col_name <- NULL
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # Essential for the pipe operator %>%
# --- Configuration ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and filter CommunesGeo.csv ---
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
select(CODCOM)
# --- Process Regions ---
regions <- st_read(file.path(INPUT_DIR, "regions.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_REGIONS) %>%
rename(nom = nom) # Assumes 'nom' column for region name
saveRDS(regions, file.path(OUTPUT_DIR, "regions_simplified.rds"))
# --- Process Departements ---
departements <- st_read(file.path(INPUT_DIR, "contour-des-departements.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_DEPARTEMENTS) %>%
rename(code = code, nom = nom) # Assumes 'code' and 'nom' columns for department
saveRDS(departements, file.path(OUTPUT_DIR, "departements_simplified.rds"))
# --- Process Communes (filtered) ---
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326) %>%
rename(GEOJSON_COMMUNE_CODE = INSEE_COM) # !!! CRITICAL: Assumes 'INSEE_COM' is the commune code column in your GeoJSON
communes_filtered_sf <- communes %>%
inner_join(df_communes_filtered, by = c("GEOJSON_COMMUNE_CODE" = "CODCOM"))
communes_filtered_simplified <- communes_filtered_sf %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_COMMUNES)
saveRDS(communes_filtered_simplified, file.path(OUTPUT_DIR, "communes_filtered_simplified.rds"))
message("Pre-processing complete. Run your Shiny app.R.")
View(communes_filtered_simplified)
View(df_communes_filtered)
View(df_communes_csv)
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # Essential for the pipe operator %>%
# --- Configuration ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and filter CommunesGeo.csv ---
message("--- Step 1: Loading and filtering CommunesGeo.csv ---")
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
message(paste("Original rows in CommunesGeo.csv:", nrow(df_communes_csv)))
# Check PMUN column before conversion
if ("PMUN" %in% colnames(df_communes_csv)) {
message(paste("PMUN column class BEFORE conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN BEFORE conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
} else {
stop("PMUN column 'PMUN' not found in CommunesGeo.csv after cleaning names. Please check the actual column name.")
}
# Convert CODCOM and PMUN
df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
# Check PMUN column after conversion
message(paste("PMUN column class AFTER conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN AFTER conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
message(paste("Number of NAs in PMUN after conversion:", sum(is.na(df_communes_csv$PMUN))))
if (sum(is.na(df_communes_csv$PMUN)) > 0) {
warning("PMUN column contains NA values after conversion. This might be due to non-numeric characters. Check original data for entries that are not valid numbers.")
# Optionally, inspect rows with NAs:
# print(df_communes_csv[is.na(df_communes_csv$PMUN), c("CODCOM", "PMUN_original_column_name_if_known")])
}
# Filter by population
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
select(CODCOM) # Only keep CODCOM for the join
message(paste("Rows in df_communes_filtered (after PMUN filter):", nrow(df_communes_filtered)))
if (nrow(df_communes_filtered) == 0) {
warning("No communes found after filtering by PMUN. This means no communes will be in the final map for this range.")
}
message("First 5 CODCOMs in df_communes_filtered (if any):")
print(head(df_communes_filtered$CODCOM, 5))
# --- Process Regions ---
message("\n--- Step 2: Processing regions.geojson ---")
regions <- st_read(file.path(INPUT_DIR, "regions.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_REGIONS) %>%
rename(nom = nom) # Assumes 'nom' column for region name (change if different)
saveRDS(regions, file.path(OUTPUT_DIR, "regions_simplified.rds"))
message("regions_simplified.rds saved.")
# --- Process Departements ---
message("\n--- Step 3: Processing contour-des-departements.geojson ---")
departements <- st_read(file.path(INPUT_DIR, "contour-des-departements.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_DEPARTEMENTS) %>%
rename(code = code, nom = nom) # Assumes 'code' and 'nom' columns for department (change if different)
saveRDS(departements, file.path(OUTPUT_DIR, "departements_simplified.rds"))
message("departements_simplified.rds saved.")
# --- Process Communes and perform join ---
message("\n--- Step 4: Processing commune-frmetdrom.geojson and performing join ---")
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326)
runApp()
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # Essential for the pipe operator %>%
# --- Configuration ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and filter CommunesGeo.csv ---
message("--- Step 1: Loading and filtering CommunesGeo.csv ---")
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
message(paste("Original rows in CommunesGeo.csv:", nrow(df_communes_csv)))
# Check PMUN column before conversion
if ("PMUN" %in% colnames(df_communes_csv)) {
message(paste("PMUN column class BEFORE conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN BEFORE conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
} else {
stop("PMUN column 'PMUN' not found in CommunesGeo.csv after cleaning names. Please check the actual column name.")
}
# Convert CODCOM and PMUN
df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
# Check PMUN column after conversion
message(paste("PMUN column class AFTER conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN AFTER conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
message(paste("Number of NAs in PMUN after conversion:", sum(is.na(df_communes_csv$PMUN))))
if (sum(is.na(df_communes_csv$PMUN)) > 0) {
warning("PMUN column contains NA values after conversion. This might be due to non-numeric characters. Check original data for entries that are not valid numbers.")
# Optionally, inspect rows with NAs:
# print(df_communes_csv[is.na(df_communes_csv$PMUN), c("CODCOM", "PMUN_original_column_name_if_known")])
}
# Filter by population
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
select(CODCOM) # Only keep CODCOM for the join
message(paste("Rows in df_communes_filtered (after PMUN filter):", nrow(df_communes_filtered)))
if (nrow(df_communes_filtered) == 0) {
warning("No communes found after filtering by PMUN. This means no communes will be in the final map for this range.")
}
message("First 5 CODCOMs in df_communes_filtered (if any):")
print(head(df_communes_filtered$CODCOM, 5))
# --- Process Regions ---
message("\n--- Step 2: Processing regions.geojson ---")
regions <- st_read(file.path(INPUT_DIR, "regions.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_REGIONS) %>%
rename(nom = nom) # Assumes 'nom' column for region name (change if different)
saveRDS(regions, file.path(OUTPUT_DIR, "regions_simplified.rds"))
message("regions_simplified.rds saved.")
# --- Process Departements ---
message("\n--- Step 3: Processing contour-des-departements.geojson ---")
departements <- st_read(file.path(INPUT_DIR, "contour-des-departements.geojson")) %>%
st_transform(crs = 4326) %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_DEPARTEMENTS) %>%
rename(code = code, nom = nom) # Assumes 'code' and 'nom' columns for department (change if different)
saveRDS(departements, file.path(OUTPUT_DIR, "departements_simplified.rds"))
message("departements_simplified.rds saved.")
# --- Process Communes and perform join ---
message("\n--- Step 4: Processing commune-frmetdrom.geojson and performing join ---")
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326)
message(paste("Original rows in commune-frmetdrom.geojson:", nrow(communes)))
message("Columns in commune-frmetdrom.geojson BEFORE renaming for join:")
print(colnames(communes))
# !!! CRITICAL: IDENTIFY AND CONFIRM THE CORRECT COMMUNE CODE COLUMN IN YOUR GEOJSON
# Change 'INSEE_COM' below if your actual column name is different (e.g., 'code', 'COM_CODE')
if ("INSEE_COM" %in% colnames(communes)) {
communes <- communes %>% rename(GEOJSON_COMMUNE_CODE = INSEE_COM)
message("Renamed 'INSEE_COM' to 'GEOJSON_COMMUNE_CODE' for join.")
} else if ("code" %in% colnames(communes)) { # Common alternative
communes <- communes %>% rename(GEOJSON_COMMUNE_CODE = code)
message("Renamed 'code' to 'GEOJSON_COMMUNE_CODE' for join.")
} else {
stop("Neither 'INSEE_COM' nor 'code' found in commune-frmetdrom.geojson for commune code. Please manually inspect your GeoJSON file to find the correct column name and adjust the 'rename()' line in this script accordingly. Available columns printed above.")
}
message("First 5 GEOJSON_COMMUNE_CODEs in GeoJSON (after potential renaming):")
print(head(communes$GEOJSON_COMMUNE_CODE, 5))
message(paste("Class of GEOJSON_COMMUNE_CODE in GeoJSON:", class(communes$GEOJSON_COMMUNE_CODE)))
message("Attempting inner join between GeoJSON and filtered CSV based on commune codes...")
communes_filtered_sf <- communes %>%
inner_join(df_communes_filtered, by = c("GEOJSON_COMMUNE_CODE" = "CODCOM"))
message(paste("Rows AFTER inner_join:", nrow(communes_filtered_sf)))
if (nrow(communes_filtered_sf) > 0) {
communes_filtered_simplified <- communes_filtered_sf %>%
st_simplify(preserveTopology = TRUE, dTolerance = TOLERANCE_COMMUNES)
saveRDS(communes_filtered_simplified, file.path(OUTPUT_DIR, "communes_filtered_simplified.rds"))
message("communes_filtered_simplified.rds saved successfully with filtered observations.")
} else {
warning("No communes found after the inner_join. The resulting 'communes_filtered_simplified.rds' file will be empty or not created.")
}
message("\nPre-processing complete. Please review the console messages for diagnostic information.")
View(df_communes_filtered)
runApp()
View(departements)
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # Essential for the pipe operator %>%
# --- Configuration ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and filter CommunesGeo.csv ---
message("--- Step 1: Loading and filtering CommunesGeo.csv ---")
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
message(paste("Original rows in CommunesGeo.csv:", nrow(df_communes_csv)))
# Check PMUN column before conversion
if ("PMUN" %in% colnames(df_communes_csv)) {
message(paste("PMUN column class BEFORE conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN BEFORE conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
} else {
stop("PMUN column 'PMUN' not found in CommunesGeo.csv after cleaning names. Please check the actual column name.")
}
# Convert CODCOM and PMUN
df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
# Check PMUN column after conversion
message(paste("PMUN column class AFTER conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN AFTER conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
message(paste("Number of NAs in PMUN after conversion:", sum(is.na(df_communes_csv$PMUN))))
if (sum(is.na(df_communes_csv$PMUN)) > 0) {
warning("PMUN column contains NA values after conversion. This might be due to non-numeric characters. Check original data for entries that are not valid numbers.")
# Optionally, inspect rows with NAs:
# print(df_communes_csv[is.na(df_communes_csv$PMUN), c("CODCOM", "PMUN_original_column_name_if_known")])
}
# Filter by population
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
message(paste("Rows in df_communes_filtered (after PMUN filter):", nrow(df_communes_filtered)))
communes <- st_read(file.path(INPUT_DIR, "commune-frmetdrom.geojson")) %>%
st_transform(crs = 4326)
# preprocess_geojson.R
# Run this script ONCE in your R console (outside of the Shiny app)
# to simplify and save the GeoJSON files for faster loading in the app.
library(sf)
library(dplyr) # Essential for the pipe operator %>%
# --- Configuration ---
INPUT_DIR <- "." # Assuming GeoJSON and CSV files are in the same directory as this script
OUTPUT_DIR <- "." # Save simplified .rds files in the same directory
TOLERANCE_COMMUNES <- 10
TOLERANCE_DEPARTEMENTS <- 50
TOLERANCE_REGIONS <- 100
# --- Load and filter CommunesGeo.csv ---
message("--- Step 1: Loading and filtering CommunesGeo.csv ---")
df_communes_csv <- read.csv(file.path(INPUT_DIR, "CommunesGeo.csv"),
sep = " ", encoding = "UTF-8", header = TRUE,
quote = "\"", dec = ".", stringsAsFactors = FALSE)
colnames(df_communes_csv) <- make.names(colnames(df_communes_csv), unique = TRUE)
message(paste("Original rows in CommunesGeo.csv:", nrow(df_communes_csv)))
# Check PMUN column before conversion
if ("PMUN" %in% colnames(df_communes_csv)) {
message(paste("PMUN column class BEFORE conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN BEFORE conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
} else {
stop("PMUN column 'PMUN' not found in CommunesGeo.csv after cleaning names. Please check the actual column name.")
}
# Convert CODCOM and PMUN
df_communes_csv$CODCOM <- as.character(trimws(df_communes_csv$CODCOM))
df_communes_csv$PMUN <- as.numeric(gsub(",", ".", trimws(as.character(df_communes_csv$PMUN))))
# Check PMUN column after conversion
message(paste("PMUN column class AFTER conversion:", class(df_communes_csv$PMUN)))
message("First 5 values of PMUN AFTER conversion (for inspection):")
print(head(df_communes_csv$PMUN, 5))
message(paste("Number of NAs in PMUN after conversion:", sum(is.na(df_communes_csv$PMUN))))
if (sum(is.na(df_communes_csv$PMUN)) > 0) {
warning("PMUN column contains NA values after conversion. This might be due to non-numeric characters. Check original data for entries that are not valid numbers.")
# Optionally, inspect rows with NAs:
# print(df_communes_csv[is.na(df_communes_csv$PMUN), c("CODCOM", "PMUN_original_column_name_if_known")])
}
# Filter by population
df_communes_filtered <- df_communes_csv %>%
filter(PMUN >= 10000 & PMUN <= 20000) %>%
message(paste("Rows in df_communes_filtered (after PMUN filter):", nrow(df_communes_filtered)))
runApp()
runApp()
runApp()
runApp()
gc()
